{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\project_meta\\NNproject\\NNI\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "root=os.path.abspath(os.path.join(r\"D:\\project_meta\\NNproject\\NNI\"))\n",
    "print(root)\n",
    "sys.path.append(root)\n",
    "os.environ[\"TORCH_HOME\"]=r\"E:\\Data\\torch-model\"\n",
    "import warnings  \n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"mne\")\n",
    "data_root=r'D:\\dataset\\driver_dataset\\DROZY\\DROZY'\n",
    "output_root=r\"D:\\project_meta\\NNproject\\NNI\\output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [3, 16, 7680]             576\n",
      "       BatchNorm1d-2              [3, 16, 7680]              32\n",
      "              ReLU-3              [3, 16, 7680]               0\n",
      "         MaxPool1d-4              [3, 16, 3839]               0\n",
      "            Conv1d-5              [3, 32, 1920]           1,568\n",
      "       BatchNorm1d-6              [3, 32, 1920]              64\n",
      "              ReLU-7              [3, 32, 1920]               0\n",
      "            Conv1d-8               [3, 64, 960]           6,208\n",
      "       BatchNorm1d-9               [3, 64, 960]             128\n",
      "             ReLU-10               [3, 64, 960]               0\n",
      "           Conv1d-11               [3, 64, 480]          12,352\n",
      "      BatchNorm1d-12               [3, 64, 480]             128\n",
      "             ReLU-13               [3, 64, 480]               0\n",
      "           Conv1d-14               [3, 64, 240]          12,352\n",
      "      BatchNorm1d-15               [3, 64, 240]             128\n",
      "             ReLU-16               [3, 64, 240]               0\n",
      "AdaptiveAvgPool1d-17                 [3, 64, 1]               0\n",
      "          Flatten-18                    [3, 64]               0\n",
      "             ReLU-19                    [3, 64]               0\n",
      "           Linear-20                    [3, 32]           2,080\n",
      "             ReLU-21                    [3, 32]               0\n",
      "           Linear-22                     [3, 4]             132\n",
      "================================================================\n",
      "Total params: 35,748\n",
      "Trainable params: 35,748\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.44\n",
      "Forward/backward pass size (MB): 21.45\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 22.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from project .model.CNN1D import *\n",
    "inputlayer=Input_Layer(5,3)\n",
    "net=simple_cnn1d(input_channels=5,num_classes=4,list_down=[16,32,64,64,64])\n",
    "from torchsummary import summary\n",
    "summary(net,(5,3*2560),batch_size=3,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input_Layer(\n",
      "  (conv1): Conv1d(5, 3, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (bn1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (maxp1): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Conv1d(5, 3, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ReLU()\n",
      "MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "inputlayer.InitalParameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_cnn1d(\n",
      "  (input_layer): Input_Layer(\n",
      "    (conv1): Conv1d(5, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (maxp1): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (down_blk0): Down_Sample_Layer(\n",
      "    (conv2): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "  )\n",
      "  (down_blk1): Down_Sample_Layer(\n",
      "    (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "  )\n",
      "  (down_blk2): Down_Sample_Layer(\n",
      "    (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "  )\n",
      "  (down_blk3): Down_Sample_Layer(\n",
      "    (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "  )\n",
      "  (classfier_layer): Classfier_Layer(\n",
      "    (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (relu1): ReLU()\n",
      "    (linear1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (linear2): Linear(in_features=32, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "Input_Layer(\n",
      "  (conv1): Conv1d(5, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (maxp1): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Conv1d(5, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ReLU()\n",
      "MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Down_Sample_Layer(\n",
      "  (conv2): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      ")\n",
      "Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ReLU()\n",
      "Down_Sample_Layer(\n",
      "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      ")\n",
      "Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ReLU()\n",
      "Down_Sample_Layer(\n",
      "  (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      ")\n",
      "Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ReLU()\n",
      "Down_Sample_Layer(\n",
      "  (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      ")\n",
      "Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ReLU()\n",
      "Classfier_Layer(\n",
      "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (relu1): ReLU()\n",
      "  (linear1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (linear2): Linear(in_features=32, out_features=4, bias=True)\n",
      ")\n",
      "AdaptiveAvgPool1d(output_size=1)\n",
      "Flatten(start_dim=1, end_dim=-1)\n",
      "ReLU()\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "ReLU()\n",
      "Linear(in_features=32, out_features=4, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for m in net.modules():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 8, 27, 64, 125]\n"
     ]
    }
   ],
   "source": [
    "def apply_func(func, sequence):\n",
    "    return [func(item) for item in sequence]\n",
    "\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "def third(x):\n",
    "    return x ** 3\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "squared_numbers = apply_func(third, numbers)\n",
    "print(squared_numbers)  # [1, 4, 9, 16, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "net=simple_cnn1d(input_channels=5,num_classes=3,list_down=[16,32,64,64,64])\n",
    "net.load_state_dict(torch.load(r'D:\\project_meta\\NNproject\\NNI\\output\\model_parameter\\FilterSignalCNN1D\\2023_11_06_20_28_11\\0_0.2962962962962963.pt'))\n",
    "f=net.__dict__['_modules']['input_layer'].__dict__['_modules']['conv1'].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=simple_cnn1d(input_channels=5,num_classes=3,list_down=[16,32,64,64,64])\n",
    "t=net.__dict__['_modules']['input_layer'].__dict__['_modules']['conv1'].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t==f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
