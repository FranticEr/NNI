{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设定路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\project_meta\\NNproject\\NNI\n",
      "datasetfolder:\n",
      "{'annotation_auto_folder': 'D:\\\\dataset\\\\driver_dataset\\\\DROZY\\\\DROZY\\\\annotations-auto',\n",
      " 'annotation_manual_folder': 'D:\\\\dataset\\\\driver_dataset\\\\DROZY\\\\DROZY\\\\annotations-manual',\n",
      " 'kinect_file': 'D:\\\\dataset\\\\driver_dataset\\\\DROZY\\\\DROZY\\\\kinect-intrinsics.yaml',\n",
      " 'kss_file': 'D:\\\\dataset\\\\driver_dataset\\\\DROZY\\\\DROZY\\\\KSS.txt',\n",
      " 'psg_folder': 'D:\\\\dataset\\\\driver_dataset\\\\DROZY\\\\DROZY\\\\psg',\n",
      " 'pvt_rt_folder': 'D:\\\\dataset\\\\driver_dataset\\\\DROZY\\\\DROZY\\\\pvt-rt',\n",
      " 'videos_folder': 'D:\\\\dataset\\\\driver_dataset\\\\DROZY\\\\DROZY\\\\videos_i8'}\n",
      "outputfolder:\n",
      "{'ECG_table_file': 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\ECG_table.csv',\n",
      " 'EEG_table_file': 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\EEG_table.csv',\n",
      " 'bandpower_file': 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\bandpower.csv',\n",
      " 'cwt_folder': 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\cwt',\n",
      " 'filted_folder': 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\psg_filted',\n",
      " 'info_file': 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\info.csv',\n",
      " 'nomalfilted_folder': 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\psg_nomalfilted',\n",
      " 'noncross_file': 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\noncross.csv',\n",
      " 'uniformbandpower_file': 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\uniformbandpower.csv',\n",
      " 'uniformfilted_folder': 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\psg_uniformfilted',\n",
      " 'video_frames': 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\video_frames'}\n"
     ]
    }
   ],
   "source": [
    "def setProjectPath(projectPath):\n",
    "    import os\n",
    "    import sys\n",
    "    root=os.path.abspath(projectPath)\n",
    "    print(root)\n",
    "    sys.path.append(root)\n",
    "    os.environ[\"TORCH_HOME\"]=r\"E:\\Data\\torch-model\"\n",
    "    import warnings  \n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"mne\")\n",
    "\n",
    "projectPath=r'D:\\project_meta\\NNproject\\NNI'\n",
    "setProjectPath(projectPath)\n",
    "import mne\n",
    "datasetFolder=r'D:\\dataset\\driver_dataset\\DROZY\\DROZY'\n",
    "outputFolder=r'D:\\project_meta\\NNproject\\NNI\\output'\n",
    "from project.dataprocess.FolderTree import *\n",
    "datasetDict=getDataPath(datasetFolder)\n",
    "outputDict=getOutPath(outputFolder)\n",
    "import pprint\n",
    "print('datasetfolder:')\n",
    "pprint.pprint(datasetDict)\n",
    "print('outputfolder:')\n",
    "pprint.pprint(outputDict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\project_meta\\NNproject\\NNI\\output\\video_frames\\IDFolder\n"
     ]
    }
   ],
   "source": [
    "IDFrameFolder=os.path.join(outputDict['video_frames'],'IDFolder')\n",
    "print(IDFrameFolder)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 调整图片大小\n",
    "    transforms.ToTensor(),  # 转换为张量\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化\n",
    "])\n",
    "\n",
    "dataset=ImageFolder(IDFrameFolder,transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\video_frames\\\\IDFolder\\\\1', 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\video_frames\\\\IDFolder\\\\2', 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\video_frames\\\\IDFolder\\\\3', 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\video_frames\\\\IDFolder\\\\4', 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\video_frames\\\\IDFolder\\\\5', 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\video_frames\\\\IDFolder\\\\6', 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\video_frames\\\\IDFolder\\\\7', 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\video_frames\\\\IDFolder\\\\8', 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\video_frames\\\\IDFolder\\\\9', 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\video_frames\\\\IDFolder\\\\10', 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\video_frames\\\\IDFolder\\\\11', 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\video_frames\\\\IDFolder\\\\12', 'D:\\\\project_meta\\\\NNproject\\\\NNI\\\\output\\\\video_frames\\\\IDFolder\\\\13']\n"
     ]
    }
   ],
   "source": [
    "person_foler=[os.path.join(IDFrameFolder,str(person)) for person in range(1,14)]\n",
    "print(person_foler)\n",
    "test_dataset = torch.utils.data.Subset(dataset, person_foler[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总样本数： 3305\n",
      "测试集样本数：3\n",
      "训练集样本数：11\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "# 数据集根目录\n",
    "data_dir = IDFrameFolder\n",
    "\n",
    "# 定义数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 调整图片大小\n",
    "    transforms.ToTensor(),  # 转换为张量\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# 获取每个人的文件夹路径\n",
    "person_folders = [os.path.join(data_dir, person) for person in os.listdir(data_dir)]\n",
    "\n",
    "# 根据需要指定测试集和训练集\n",
    "test_persons = [2, 5, 9]  # 假设选择第2、第5和第9个人作为测试集\n",
    "train_persons = [idx for idx in range(0, 14) if idx not in test_persons]  # 其他人作为训练集\n",
    "\n",
    "# 创建测试集和训练集的数据加载器\n",
    "test_dataset = torch.utils.data.Subset(dataset, [person_folders[person] for person in test_persons])\n",
    "train_dataset = torch.utils.data.Subset(dataset, [person_folders[person] for person in train_persons])\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 打印数据集信息\n",
    "print(f\"总样本数： {len(dataset)}\")\n",
    "print(f\"测试集样本数：{len(test_dataset)}\")\n",
    "print(f\"训练集样本数：{len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3, 4, 6, 7, 8, 10, 11, 12, 13]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总样本数： 3305\n",
      "测试集样本数：2\n",
      "训练集样本数：12\n",
      "总样本数： 3305\n",
      "测试集样本数：2\n",
      "训练集样本数：12\n",
      "总样本数： 3305\n",
      "测试集样本数：2\n",
      "训练集样本数：12\n",
      "总样本数： 3305\n",
      "测试集样本数：2\n",
      "训练集样本数：12\n",
      "总样本数： 3305\n",
      "测试集样本数：2\n",
      "训练集样本数：12\n",
      "总样本数： 3305\n",
      "测试集样本数：2\n",
      "训练集样本数：12\n",
      "总样本数： 3305\n",
      "测试集样本数：2\n",
      "训练集样本数：12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "personId=list(range(1,15))\n",
    "\n",
    "kf = KFold(n_splits=7, shuffle=True, random_state=42)\n",
    "for kt_i,(train_persons,test_persons) in enumerate(kf.split(person_folders)):\n",
    "    # test_persons = [2, 5, 9]  # 假设选择第2、第5和第9个人作为测试集\n",
    "    # train_persons = [idx for idx in range(0, 14) if idx not in test_persons]  # 其他人作为训练集\n",
    "\n",
    "    # 创建测试集和训练集的数据加载器\n",
    "    test_dataset = torch.utils.data.Subset(dataset, [person_folders[person] for person in test_persons])\n",
    "    train_dataset = torch.utils.data.Subset(dataset, [person_folders[person] for person in train_persons])\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # 打印数据集信息\n",
    "    print(f\"总样本数： {len(dataset)}\")\n",
    "    print(f\"测试集样本数：{len(test_dataset)}\")\n",
    "    print(f\"训练集样本数：{len(train_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总样本数：3305\n",
      "5折交叉验证\n",
      "第1次验证集大小：0\n",
      "第2次验证集大小：0\n",
      "第3次验证集大小：0\n",
      "第4次验证集大小：0\n",
      "第5次验证集大小：0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "# 数据集根目录\n",
    "data_dir =  IDFrameFolder\n",
    "\n",
    "# 定义数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 调整图片大小\n",
    "    transforms.ToTensor(),  # 转换为张量\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# 获取每个人的文件夹路径及人的编号\n",
    "person_folders = [(os.path.join(data_dir, person), person) for person in os.listdir(data_dir)]\n",
    "\n",
    "# 将人的索引作为字典的键，将每个人的图片路径保存在对应的列表中\n",
    "person_images = defaultdict(list)\n",
    "for folder, person in person_folders:\n",
    "    filenames = os.listdir(folder)\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            path = os.path.join(folder, filename)\n",
    "            person_images[person].append(path)\n",
    "\n",
    "# 以人为单位划分K折\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 分割索引\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "for _, test_persons in kf.split(person_folders):\n",
    "    # 选中测试集的人的编号\n",
    "    test_person_ids = [person_folders[i][1] for i in test_persons]\n",
    "    # 将每个人的图片按照选中的测试集和训练集划分\n",
    "    train_files = []\n",
    "    test_files = []\n",
    "    for person, images in person_images.items():\n",
    "        if person in test_person_ids:\n",
    "            test_files.extend(images)\n",
    "        else:\n",
    "            train_files.extend(images)\n",
    "    # 记录训练集和测试集的索引\n",
    "    train_indices.append([dataset.index(x) for x in train_files])\n",
    "    test_indices.append([dataset.index(x) for x in test_files])\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loaders = []\n",
    "test_loaders = []\n",
    "for i in range(5):\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices[i])\n",
    "    test_sampler = torch.utils.data.SubsetRandomSampler(test_indices[i])\n",
    "    train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=32, sampler=test_sampler)\n",
    "    train_loaders.append(train_loader)\n",
    "    test_loaders.append(test_loader)\n",
    "\n",
    "# 打印数据集和交叉验证信息\n",
    "print(f\"总样本数：{len(dataset)}\")\n",
    "print(f\"{kf.n_splits}折交叉验证\")\n",
    "for i in range(kf.n_splits):\n",
    "    print(f\"第{i+1}次验证集大小：{len(test_indices[i])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
