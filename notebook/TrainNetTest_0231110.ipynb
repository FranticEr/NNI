{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "net=torch.nn.Linear(2,4)\n",
    "optim=torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "loss=torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBatch(net,x,y,optimizer,lossFunction):\n",
    "    optim.zero_grad()\n",
    "    y_hat=net(torch.tensor([[1,2]]).to(torch.float32))\n",
    "    l=loss(y_hat,y)\n",
    "    l.backward()\n",
    "    optim.step()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1537, -0.4658],\n",
       "         [ 0.0176, -0.6108],\n",
       "         [-0.0918, -0.4873],\n",
       "         [ 0.1385, -0.3450]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0649,  0.6815,  0.5312, -0.2131], requires_grad=True)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1747, -0.4867],\n",
       "         [-0.0034, -0.6317],\n",
       "         [-0.0709, -0.4663],\n",
       "         [ 0.1175, -0.3659]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0859,  0.6606,  0.5522, -0.2341], requires_grad=True)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainBatch(net,1,torch.tensor([2]))\n",
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBatch(net,x,y,optimizer,lossFunction):\n",
    "    optimizer.zero_grad()\n",
    "    y_hat=net(x)\n",
    "    loss=lossFunction(y_hat,y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return y,y_hat,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XYSeparateFunion(batchData):\n",
    "    xBatch=0\n",
    "    yBatch=0\n",
    "    return xBatch,yBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainOneEpoch(net,dataloader,XYSeparateFunion,optimizer,lossFunction):\n",
    "    epochY=torch.tensor([])\n",
    "    epochLoss=torch.tensor([])\n",
    "    epochYhat=torch.tensor([])\n",
    "    for i,data in enumerate(dataloader):\n",
    "        y,y_hat,loss=trainBatch(net,dataloader,optimizer,lossFunction)\n",
    "        torch\n",
    "    return loss,y,y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵：\n",
      "[[2 1 0]\n",
      " [0 2 0]\n",
      " [0 1 2]]\n",
      "每个类别的数量：\n",
      "[3 2 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# 实际和预测标签列表示例\n",
    "y_true = [0, 1, 0, 2, 1, 0, 2, 2]\n",
    "y_pred = [0, 1, 1, 2, 1, 0, 1, 2]\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# 计算每个类别的数量\n",
    "class_counts = np.sum(cm, axis=1)\n",
    "\n",
    "# 打印混淆矩阵和每个类别的数量\n",
    "print(\"混淆矩阵：\")\n",
    "print(cm)\n",
    "print(\"每个类别的数量：\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpochs(net,traindataloader,testdataloader,XYSeparateFunion,optimiser,lossFuntion):\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFoldTrain(net,K,dataset,optimiser,lossFuntion):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTrainLog(graph,trainAccList,testAccList,lossList,trainIndex,testIndex):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyseDataset(dataset):\n",
    "    classDict={'classnum','classname','samplesize'}\n",
    "    return classDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(y,y_hat):\n",
    "    \n",
    "    pass\n",
    "def drawConfusionMatrix(confusionMatrix):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自动训练器类\n",
    "1. 输入：net,dataloader \n",
    "2. 需要自定义的部分：trainBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a=torch.tensor([1,2,3,4,5])\n",
    "b=torch.tensor([[1,2,3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "list=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 3, 4, 5]), tensor([1, 2, 3, 4, 5])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list.append(a)\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\project_meta\\NNproject\\NNI\\notebook\\TrainNetTest_0231110.ipynb 单元格 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/project_meta/NNproject/NNI/notebook/TrainNetTest_0231110.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49mtensor(\u001b[39mlist\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "torch.tensor(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat=torch.tensor([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.],\n",
       "        [1., 2., 3., 4., 5.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat=torch.concat([concat,b],dim=0)\n",
    "concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 类方法调用包中的方法是为了方法的分离性，保证方法可以单独被调用，而不是与类绑定的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassfierTrainer():\n",
    "    def __init__(self,net,epochNum,optimizer,lossFuntion):\n",
    "        self.Net=net\n",
    "        self.EpcochNum=epochNum\n",
    "        self.Optimizer=optimizer\n",
    "        self.LossFuntion=lossFuntion\n",
    "        pass\n",
    "\n",
    "    def __call__(self):\n",
    "        self.run()\n",
    "        pass\n",
    "    \n",
    "    def SetNet(self):\n",
    "        pass\n",
    "    def SetEpochNum(self):\n",
    "        pass\n",
    "    def SetDataloader(self):\n",
    "        pass\n",
    "    def SplitDataloader(self):\n",
    "        pass\n",
    "    def run(self):\n",
    "        \n",
    "        pass\n",
    "    def TrainBatch(self):\n",
    "        pass\n",
    "    def TrainOneEpoch(self):\n",
    "        pass\n",
    "    def TrainEpochs(self):\n",
    "        pass\n",
    "    def Statitics(self):\n",
    "        pass\n",
    "    def KflodTrain(self):\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=ClassfierTrainer(net,3,optim,torch.nn.L1Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.Net\n",
    "a.Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# project文件测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\project_meta\\NNproject\\NNI\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "root=os.path.abspath(os.path.join(r\"D:\\project_meta\\NNproject\\NNI\\notebook\\NNITest_0231104.ipynb\",\"../..\"))\n",
    "print(root)\n",
    "sys.path.append(root)\n",
    "os.environ[\"TORCH_HOME\"]=r\"E:\\Data\\torch-model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.train.classfierTrainer import ClassfierTrainer\n",
    "from torch import nn,optim\n",
    "net=nn.Linear(2,3)\n",
    "optimizer=optim.Adam(net.parameters(),lr=0.001)\n",
    "lossFuction=nn.CrossEntropyLoss()\n",
    "CT=ClassfierTrainer(net=net,optimizer=optimizer,lossFuntion=lossFuction,epochNum=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn\n"
     ]
    }
   ],
   "source": [
    "class base:\n",
    "    def __init__(self,a):\n",
    "        print(a)\n",
    "class son(base):\n",
    "    def __init__(self,b):\n",
    "        super().__init__(b)\n",
    "    def XYSeparateFunion(fun,data):\n",
    "        xBatch,yBatch=fun(data)\n",
    "        return xBatch,yBatch\n",
    "a='nn'\n",
    "def xys(data):\n",
    "    return data[0],data[1]\n",
    "s=son(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss\n"
     ]
    }
   ],
   "source": [
    "def fun(a):\n",
    "    print(a)\n",
    "def ff(f):\n",
    "    f('ss')\n",
    "ff(fun) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用逻辑\n",
    "- 固定内容：trainBatch(),trainOneEpochs(),trainEpochs()\n",
    "- 不固定的内容：dataloader,net,optimizer,lossfuntcion,dataloader不确定带来的问题就是读dataloader时的不确定\n",
    "- 解决dataloader带来的不确定性的方法：\n",
    "  1. 标准化dataset\n",
    "  2. 引入dataloader读取程序\n",
    "  3. 每次重写trainBatch/trainOneEpoch\n",
    "  - 总结：最靠谱的方法时标准化dataset \n",
    "  - 可以通过继承dataset类在__getiterm__中分出多个子类\n",
    "- 写好trainer后，只需要根据需要给训练添加装饰器即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.train.operation import *\n",
    "from torch import nn\n",
    "net=nn.Linear(2,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8845,  0.1390, -1.4317]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn([1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "a=[1,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 4, 4, 4, 4, 4, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "a.insert(0,4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 1, 3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\project_meta\\NNproject\\NNI\\notebook\\TrainNetTest_0231110.ipynb 单元格 37\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/project_meta/NNproject/NNI/notebook/TrainNetTest_0231110.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mtuple\u001b[39;49m(\u001b[39mlist\u001b[39;49m((\u001b[39m1\u001b[39;49m,\u001b[39m3\u001b[39;49m))\u001b[39m.\u001b[39;49minsert(\u001b[39m0\u001b[39;49m,\u001b[39m3\u001b[39;49m))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "tuple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape=[1,3]\n",
    "length=3\n",
    "shape.insert(0,length)\n",
    "\n",
    "TestData=torch.randn(shape)\n",
    "TestData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from typing import Any\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,shape:list):\n",
    "        self.TestData=torch.randn(shape)\n",
    "        self.label=torch.randn([shape[0]])\n",
    "    def __len__(self):\n",
    "        return len(self.TestData)\n",
    "    def __getitem__(self, index) -> Any:\n",
    "        return self.TestData[index],self.label[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataset=TestDataset([100,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.2200, -0.9177, -1.1106]), tensor(-0.1218))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdataset[0][0],testdataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3711], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=nn.Linear(3,1)\n",
    "net(testdataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import *\n",
    "testdataset=TestDataset([100,1,3])\n",
    "dataloader=DataLoader(testdataset,batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[[ 0.7733,  0.2821, -0.0801]],\n",
       "  \n",
       "          [[ 0.3697, -1.0479,  0.0624]]]),\n",
       "  tensor([0.3575, 0.2307])],\n",
       " [tensor([[[ 0.6849,  1.2877,  3.3969]],\n",
       "  \n",
       "          [[ 0.7287,  1.9938, -0.6530]]]),\n",
       "  tensor([0.0223, 0.6444])],\n",
       " [tensor([[[-1.4314, -1.8274,  0.5222]],\n",
       "  \n",
       "          [[-2.1946, -1.7025,  0.6805]]]),\n",
       "  tensor([1.6951, 1.1413])],\n",
       " [tensor([[[-0.9726, -0.9064, -0.7550]],\n",
       "  \n",
       "          [[ 0.2623,  2.0315, -0.6698]]]),\n",
       "  tensor([-0.0838, -1.7212])],\n",
       " [tensor([[[-0.8926,  0.4090,  1.8849]],\n",
       "  \n",
       "          [[-1.6250, -0.3731, -0.3072]]]),\n",
       "  tensor([-1.4775, -0.5087])],\n",
       " [tensor([[[ 1.7758, -0.5382, -0.5731]],\n",
       "  \n",
       "          [[ 0.4149, -0.7815, -0.6390]]]),\n",
       "  tensor([ 0.1852, -0.3218])],\n",
       " [tensor([[[ 0.0494, -1.1059,  0.0981]],\n",
       "  \n",
       "          [[-1.6352, -0.4780,  0.7897]]]),\n",
       "  tensor([1.0751, 1.7171])],\n",
       " [tensor([[[ 0.5188, -1.3945, -0.1816]],\n",
       "  \n",
       "          [[ 1.3527, -0.2515,  0.1302]]]),\n",
       "  tensor([0.2049, 0.1033])],\n",
       " [tensor([[[ 0.9082,  0.2878, -0.2668]],\n",
       "  \n",
       "          [[-1.0392, -0.6178,  1.1596]]]),\n",
       "  tensor([-1.4692,  1.5261])],\n",
       " [tensor([[[ 1.2197, -0.9531,  3.2548]],\n",
       "  \n",
       "          [[ 0.3034, -0.9468,  1.5468]]]),\n",
       "  tensor([-0.4337,  1.1239])],\n",
       " [tensor([[[-0.3493, -0.5276,  0.6481]],\n",
       "  \n",
       "          [[-0.3587, -1.0719,  0.6345]]]),\n",
       "  tensor([-1.6968, -0.9601])],\n",
       " [tensor([[[-0.3951, -1.2974,  0.1833]],\n",
       "  \n",
       "          [[ 1.1142,  1.4982,  0.4821]]]),\n",
       "  tensor([-0.7520, -0.3151])],\n",
       " [tensor([[[ 0.4797, -0.1032,  0.7111]],\n",
       "  \n",
       "          [[-0.2050,  0.1240,  0.6035]]]),\n",
       "  tensor([0.8411, 0.4049])],\n",
       " [tensor([[[-0.3658,  0.5357, -0.5960]],\n",
       "  \n",
       "          [[ 0.1966, -0.9385,  0.4651]]]),\n",
       "  tensor([-1.5503, -0.2065])],\n",
       " [tensor([[[-0.8611,  0.9804,  0.4170]],\n",
       "  \n",
       "          [[ 1.1770,  0.2374,  0.3343]]]),\n",
       "  tensor([0.9976, 0.1024])],\n",
       " [tensor([[[ 0.0436,  0.7863, -0.1155]],\n",
       "  \n",
       "          [[ 0.9815,  0.8354,  0.1330]]]),\n",
       "  tensor([1.4893, 1.0914])],\n",
       " [tensor([[[ 1.3186, -0.7114,  0.6376]],\n",
       "  \n",
       "          [[ 1.3841, -0.7414, -0.4086]]]),\n",
       "  tensor([0.5882, 0.4532])],\n",
       " [tensor([[[ 0.7550, -1.0024,  0.2162]],\n",
       "  \n",
       "          [[-1.0138,  2.4075, -1.6645]]]),\n",
       "  tensor([-0.3163,  0.8789])],\n",
       " [tensor([[[ 1.4399,  1.1020,  0.0121]],\n",
       "  \n",
       "          [[-2.0552,  0.1883,  0.6490]]]),\n",
       "  tensor([-0.0357, -0.1736])],\n",
       " [tensor([[[ 0.1095, -0.4324,  1.2798]],\n",
       "  \n",
       "          [[-1.0222,  0.3352, -0.0917]]]),\n",
       "  tensor([-0.6818,  0.1957])],\n",
       " [tensor([[[-0.2648,  0.2773,  1.2992]],\n",
       "  \n",
       "          [[-0.8858, -0.0271, -0.2532]]]),\n",
       "  tensor([-0.2572, -0.6268])],\n",
       " [tensor([[[-2.9644e-01,  4.6320e-01,  1.9143e-04]],\n",
       "  \n",
       "          [[ 1.9462e+00,  6.6515e-01, -9.1386e-02]]]),\n",
       "  tensor([-1.8059,  0.1559])],\n",
       " [tensor([[[-0.2889,  0.8599,  1.2528]],\n",
       "  \n",
       "          [[-0.2824, -0.0048,  0.9757]]]),\n",
       "  tensor([-0.9251,  0.0633])],\n",
       " [tensor([[[-0.4189,  0.2626, -0.9235]],\n",
       "  \n",
       "          [[ 0.3929, -0.8088, -0.1052]]]),\n",
       "  tensor([-0.9100,  0.6610])],\n",
       " [tensor([[[ 0.3732,  1.0978,  1.6040]],\n",
       "  \n",
       "          [[-0.0608,  0.9943,  0.8108]]]),\n",
       "  tensor([-0.0369, -1.4415])],\n",
       " [tensor([[[-0.2410, -0.5971,  1.2075]],\n",
       "  \n",
       "          [[ 1.6126, -0.5394, -0.6805]]]),\n",
       "  tensor([-0.9225, -0.0869])],\n",
       " [tensor([[[-0.1998,  1.7139, -0.7825]],\n",
       "  \n",
       "          [[ 0.3205,  1.2463,  1.2669]]]),\n",
       "  tensor([-0.4183,  1.3562])],\n",
       " [tensor([[[-0.1636, -0.3464,  0.0718]],\n",
       "  \n",
       "          [[ 1.2627,  2.0536,  1.7492]]]),\n",
       "  tensor([ 0.5341, -0.1172])],\n",
       " [tensor([[[-0.2246, -0.4949,  1.3234]],\n",
       "  \n",
       "          [[-0.7267,  0.1690, -0.4715]]]),\n",
       "  tensor([-0.4194,  1.4836])],\n",
       " [tensor([[[ 0.0535,  0.0281, -1.1139]],\n",
       "  \n",
       "          [[-1.5927,  0.1487, -1.2896]]]),\n",
       "  tensor([ 0.6386, -0.8975])],\n",
       " [tensor([[[ 0.6151,  1.6227,  0.3604]],\n",
       "  \n",
       "          [[ 1.2551, -0.2635,  0.2687]]]),\n",
       "  tensor([ 0.1856, -0.1576])],\n",
       " [tensor([[[ 0.2636,  0.8575, -0.7206]],\n",
       "  \n",
       "          [[ 0.9580,  0.3911, -0.3291]]]),\n",
       "  tensor([ 1.0152, -0.1273])],\n",
       " [tensor([[[-0.3632,  0.5283, -0.3535]],\n",
       "  \n",
       "          [[-0.2610,  0.0747,  0.0698]]]),\n",
       "  tensor([ 0.3012, -0.0329])],\n",
       " [tensor([[[-0.5011, -0.7000, -0.2368]],\n",
       "  \n",
       "          [[-0.2408,  0.6932, -0.4752]]]),\n",
       "  tensor([-1.4813, -0.2707])],\n",
       " [tensor([[[ 0.0420,  0.6400,  1.4281]],\n",
       "  \n",
       "          [[ 0.5397,  0.6005, -1.3498]]]),\n",
       "  tensor([ 0.4122, -0.5063])],\n",
       " [tensor([[[ 0.6463,  0.7813, -1.3297]],\n",
       "  \n",
       "          [[ 2.1391, -0.2406, -1.1040]]]),\n",
       "  tensor([ 0.5184, -0.7427])],\n",
       " [tensor([[[-1.9579,  0.1076, -0.1283]],\n",
       "  \n",
       "          [[-0.0804, -1.0433, -0.2068]]]),\n",
       "  tensor([1.1916, 1.2537])],\n",
       " [tensor([[[-0.5326, -0.5831,  0.6018]],\n",
       "  \n",
       "          [[ 0.8549,  1.1986, -0.6267]]]),\n",
       "  tensor([-0.0044, -0.0655])],\n",
       " [tensor([[[ 1.6867, -0.4498,  0.4320]],\n",
       "  \n",
       "          [[ 1.3747, -1.9456, -1.3424]]]),\n",
       "  tensor([-0.1641, -1.5257])],\n",
       " [tensor([[[-0.3653,  1.2043, -0.9506]],\n",
       "  \n",
       "          [[ 0.0407, -0.3547,  1.5621]]]),\n",
       "  tensor([-0.2023,  1.0199])],\n",
       " [tensor([[[-0.6603, -0.8711,  0.5554]],\n",
       "  \n",
       "          [[ 0.0850,  1.5456, -0.2201]]]),\n",
       "  tensor([1.2073, 0.5653])],\n",
       " [tensor([[[ 0.2011, -1.6713, -0.0032]],\n",
       "  \n",
       "          [[-1.4405, -0.2217,  0.2734]]]),\n",
       "  tensor([-1.0836,  1.0388])],\n",
       " [tensor([[[ 1.9928, -1.2278,  0.8767]],\n",
       "  \n",
       "          [[-0.3386, -1.4123, -0.2538]]]),\n",
       "  tensor([-1.8551,  0.9801])],\n",
       " [tensor([[[ 1.0202, -0.5984, -1.4272]],\n",
       "  \n",
       "          [[ 0.8184,  1.0072, -0.5145]]]),\n",
       "  tensor([-0.6228,  0.4821])],\n",
       " [tensor([[[-1.7631, -0.6745, -1.1726]],\n",
       "  \n",
       "          [[-0.6438,  0.0229, -1.1456]]]),\n",
       "  tensor([-1.0266,  0.5966])],\n",
       " [tensor([[[-0.8733, -2.7216, -0.4257]],\n",
       "  \n",
       "          [[ 1.7808, -0.7728,  0.9794]]]),\n",
       "  tensor([ 0.0890, -0.4920])],\n",
       " [tensor([[[ 0.5104,  1.5335, -2.3414]],\n",
       "  \n",
       "          [[-1.4269, -0.3432,  0.1446]]]),\n",
       "  tensor([-0.7600, -1.9557])],\n",
       " [tensor([[[ 0.2835, -0.2352, -0.5279]],\n",
       "  \n",
       "          [[ 0.4019, -0.8115,  0.7108]]]),\n",
       "  tensor([-0.3715,  0.3564])],\n",
       " [tensor([[[ 0.9001, -0.5039,  0.6302]],\n",
       "  \n",
       "          [[-1.9312, -0.5823,  1.1362]]]),\n",
       "  tensor([-0.8252,  0.7723])],\n",
       " [tensor([[[ 0.0865, -1.3944, -0.5735]],\n",
       "  \n",
       "          [[ 0.4692,  0.5889,  0.6716]]]),\n",
       "  tensor([-0.4971, -0.4477])]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\project_meta\\NNproject\\NNI\n",
      "D:\\project_meta\\NNproject\\NNI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 2.0716, -0.1792]),\n",
       " tensor([[1.1825],\n",
       "         [1.0865]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "root=os.path.abspath(r\"D:\\project_meta\\NNproject\\NNI\")\n",
    "print(root)\n",
    "sys.path.append(root)\n",
    "os.environ[\"TORCH_HOME\"]=r\"E:\\Data\\torch-model\"\n",
    "from project.train.operation import *\n",
    "from torch.utils.data import *\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from typing import Any\n",
    "import os\n",
    "import sys\n",
    "root=os.path.abspath(r\"D:\\project_meta\\NNproject\\NNI\")\n",
    "print(root)\n",
    "sys.path.append(root)\n",
    "os.environ[\"TORCH_HOME\"]=r\"E:\\Data\\torch-model\"\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,shape:list):\n",
    "        self.TestData=torch.randn(shape)\n",
    "        self.label=torch.randn([shape[0]])\n",
    "    def __len__(self):\n",
    "        return len(self.TestData)\n",
    "    def __getitem__(self, index) -> Any:\n",
    "        return self.TestData[index],self.label[index]\n",
    "    \n",
    "featureNum=3\n",
    "from torch.utils.data import *\n",
    "testdataset=TestDataset([100,featureNum])\n",
    "dataloader=DataLoader(testdataset,batch_size=2)\n",
    "\n",
    "\n",
    "net=nn.Linear(3,1)\n",
    "batchData=next(iter(dataloader))\n",
    "forwardBatch(net=net,batchData=batchData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\install\\anaconda\\envs\\nni\\lib\\site-packages\\torch\\nn\\modules\\loss.py:101: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "optimizer=torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "lossFunction=nn.L1Loss()\n",
    "y,y_hat,loss=trainBatch(net,batchData,optimizer,lossFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34423354268074036"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochLoss=torch.tensor([])\n",
    "epochLoss=torch.concat([epochLoss,torch.tensor([loss.item()])],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2.0716e+00, -1.7921e-01, -1.7834e+00,  3.7834e-01,  6.7764e-01,\n",
       "          9.6100e-02, -8.8062e-01, -4.8040e-01, -4.4534e-01, -8.3358e-01,\n",
       "         -1.2237e-01, -1.6676e-01, -2.9686e-01, -7.6496e-01, -5.5224e-01,\n",
       "          1.7918e+00,  3.6348e-01, -6.5663e-01, -1.4359e-01,  5.0950e-01,\n",
       "         -6.4507e-01, -1.1251e+00,  1.7320e+00,  2.0487e-01,  3.0457e-03,\n",
       "          7.7596e-01,  2.0037e-01,  7.4924e-01, -5.6603e-02,  9.6885e-01,\n",
       "          7.7617e-01,  1.9924e-01, -8.8615e-01,  1.4182e+00, -6.7848e-01,\n",
       "         -7.6258e-01, -3.3255e+00, -8.8864e-01,  3.8632e-01,  4.6204e-01,\n",
       "         -7.5691e-01, -3.9685e-01,  4.6187e-01,  4.6527e-01, -8.7046e-01,\n",
       "         -1.0716e+00,  2.2237e-02,  1.8187e-01, -1.7897e+00, -1.2175e+00,\n",
       "          4.0050e-01,  1.1412e+00,  1.5698e+00, -9.5658e-01, -7.4454e-01,\n",
       "         -4.3416e-01,  1.0574e+00,  1.5056e+00,  4.7902e-01, -1.7557e-01,\n",
       "         -1.1451e+00,  7.2585e-01, -1.3359e-01, -3.0926e-01,  1.3283e-01,\n",
       "          1.5146e-01, -1.3076e+00,  2.0227e-01, -5.9319e-01, -5.4522e-01,\n",
       "          6.5456e-01,  1.4302e+00,  1.8516e+00,  6.7187e-01, -2.3997e+00,\n",
       "          3.4864e-01, -1.3395e-01, -1.5063e+00, -8.4257e-01,  7.0669e-01,\n",
       "          1.2644e+00,  1.2163e+00,  2.8775e-01,  7.5989e-01,  9.1108e-01,\n",
       "          2.1233e-01, -8.3449e-01, -3.4214e+00,  1.8540e+00,  1.0665e+00,\n",
       "         -6.8519e-01, -1.0651e+00, -3.0908e-01,  8.2808e-01, -1.4075e+00,\n",
       "          1.1320e+00, -5.6883e-01,  1.2311e+00, -2.5563e-01, -8.1843e-01]),\n",
       " tensor([[ 1.1825],\n",
       "         [ 1.0865],\n",
       "         [-0.1992],\n",
       "         [ 1.4571],\n",
       "         [ 0.1426],\n",
       "         [-0.9410],\n",
       "         [-0.0072],\n",
       "         [ 0.1400],\n",
       "         [-1.6721],\n",
       "         [ 1.0804],\n",
       "         [-0.4803],\n",
       "         [-1.0290],\n",
       "         [ 0.9253],\n",
       "         [-0.5829],\n",
       "         [ 0.9159],\n",
       "         [-0.1772],\n",
       "         [-1.0449],\n",
       "         [ 0.7072],\n",
       "         [ 0.2506],\n",
       "         [ 0.5955],\n",
       "         [ 1.2991],\n",
       "         [ 0.7966],\n",
       "         [ 0.7721],\n",
       "         [-0.1772],\n",
       "         [-0.2375],\n",
       "         [-0.1457],\n",
       "         [ 0.2280],\n",
       "         [-0.5015],\n",
       "         [-0.6209],\n",
       "         [ 0.7063],\n",
       "         [ 1.9830],\n",
       "         [ 1.2883],\n",
       "         [ 0.7727],\n",
       "         [ 1.5367],\n",
       "         [-0.4270],\n",
       "         [ 1.6139],\n",
       "         [ 1.6074],\n",
       "         [ 0.1431],\n",
       "         [-0.0414],\n",
       "         [-0.2017],\n",
       "         [-0.7602],\n",
       "         [ 0.2995],\n",
       "         [ 0.9301],\n",
       "         [ 1.3716],\n",
       "         [ 0.6979],\n",
       "         [-0.6793],\n",
       "         [ 0.5656],\n",
       "         [-0.8062],\n",
       "         [-0.5349],\n",
       "         [-0.5952],\n",
       "         [ 0.4394],\n",
       "         [ 0.1578],\n",
       "         [ 0.2335],\n",
       "         [ 0.9903],\n",
       "         [-0.4209],\n",
       "         [ 2.4024],\n",
       "         [-0.7855],\n",
       "         [-1.1436],\n",
       "         [ 1.3417],\n",
       "         [-0.5713],\n",
       "         [ 0.8178],\n",
       "         [-0.1835],\n",
       "         [ 0.5083],\n",
       "         [-0.1108],\n",
       "         [-0.4499],\n",
       "         [ 0.8253],\n",
       "         [ 0.6351],\n",
       "         [ 0.8637],\n",
       "         [-0.7445],\n",
       "         [ 0.5339],\n",
       "         [-0.3576],\n",
       "         [-0.6390],\n",
       "         [-1.9029],\n",
       "         [ 0.9586],\n",
       "         [ 0.2067],\n",
       "         [ 0.2244],\n",
       "         [-1.0058],\n",
       "         [-0.0372],\n",
       "         [ 1.3456],\n",
       "         [-0.3507],\n",
       "         [-0.1361],\n",
       "         [ 0.4423],\n",
       "         [ 1.8590],\n",
       "         [ 0.8740],\n",
       "         [-1.6777],\n",
       "         [ 0.2964],\n",
       "         [ 0.8983],\n",
       "         [-1.5267],\n",
       "         [-1.0065],\n",
       "         [ 0.9128],\n",
       "         [-0.7712],\n",
       "         [ 0.0799],\n",
       "         [ 1.2591],\n",
       "         [ 1.1344],\n",
       "         [-1.2910],\n",
       "         [ 0.1889],\n",
       "         [ 0.8321],\n",
       "         [ 0.6304],\n",
       "         [ 0.5599],\n",
       "         [ 0.4963]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalOneEpoch(net,dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4158, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9615, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6554, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7426, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3452, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8609, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8976, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8243, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5819, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9856, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1887, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2180, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5890, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8031, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8416, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4595, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9538, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1380, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5138, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9918, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4034, grad_fn=<MeanBackward0>)\n",
      "tensor(2.3305, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0271, grad_fn=<MeanBackward0>)\n",
      "tensor(1.4185, grad_fn=<MeanBackward0>)\n",
      "tensor(1.7564, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0228, grad_fn=<MeanBackward0>)\n",
      "tensor(1.8212, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7938, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2512, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5172, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0467, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2211, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6804, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6556, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0479, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4445, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0695, grad_fn=<MeanBackward0>)\n",
      "tensor(1.4880, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7428, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1425, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7595, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0687, grad_fn=<MeanBackward0>)\n",
      "tensor(2.1399, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4200, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9456, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0067, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8506, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2386, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0468, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3371, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochY': tensor([ 0.6712,  2.3857,  0.7127, -1.0651, -1.1407,  0.1701,  0.8657,  0.0117,\n",
       "         -0.0870,  2.1618,  0.9958, -0.7260,  0.4007, -0.4403,  0.7307,  0.2917,\n",
       "          0.4259, -0.7379, -0.9820,  0.9892,  1.5229, -0.8545,  0.0983,  1.1406,\n",
       "          0.9187,  1.2290, -0.5788, -1.5400,  1.1424, -0.5408,  0.4703,  0.9244,\n",
       "          0.9605, -0.7266,  0.4614, -1.3394,  0.3943, -0.6145, -0.3748,  1.1281,\n",
       "         -0.3883, -1.0440, -1.1175, -1.9388, -0.8537,  0.4723,  1.8873,  1.5299,\n",
       "         -0.6787, -1.6343, -0.2545,  1.7904, -0.4338, -1.1827,  0.8505, -0.7089,\n",
       "          1.6991,  1.5270, -0.1003,  0.9342, -1.0106,  1.0177, -1.1067,  1.1425,\n",
       "         -0.6353,  0.2234,  0.6294, -0.6817, -0.5674,  1.5285, -0.6985,  0.0148,\n",
       "         -0.4988,  1.6402, -0.0156,  1.9922, -0.4487,  0.4330, -1.1302,  1.1548,\n",
       "          0.2015, -0.5014, -0.0995, -0.6425, -1.6156, -0.8307, -0.2232,  0.3382,\n",
       "         -0.7789,  1.1122,  1.2095, -0.8039, -1.2079, -0.8095,  0.0850, -0.2426,\n",
       "          0.3785, -1.3195,  0.8738,  0.3655]),\n",
       " 'epochYhat': tensor([[-0.4459],\n",
       "         [ 1.0297],\n",
       "         [ 0.8579],\n",
       "         [ 0.2340],\n",
       "         [-1.0071],\n",
       "         [ 0.0966],\n",
       "         [-0.4056],\n",
       "         [ 1.0796],\n",
       "         [-0.5285],\n",
       "         [ 0.2423],\n",
       "         [ 0.2978],\n",
       "         [ 0.2305],\n",
       "         [-1.3946],\n",
       "         [-0.3700],\n",
       "         [ 0.4826],\n",
       "         [-0.9179],\n",
       "         [-0.7087],\n",
       "         [ 0.2683],\n",
       "         [ 0.9855],\n",
       "         [ 0.3315],\n",
       "         [ 0.7130],\n",
       "         [-0.8123],\n",
       "         [-1.2954],\n",
       "         [ 0.3514],\n",
       "         [ 0.7465],\n",
       "         [ 0.2234],\n",
       "         [-0.9845],\n",
       "         [ 0.0663],\n",
       "         [ 0.6783],\n",
       "         [-0.3389],\n",
       "         [ 0.2518],\n",
       "         [ 0.2239],\n",
       "         [ 0.3487],\n",
       "         [-0.9471],\n",
       "         [-0.3040],\n",
       "         [ 0.9366],\n",
       "         [ 0.4130],\n",
       "         [-0.3803],\n",
       "         [ 0.4950],\n",
       "         [-0.8554],\n",
       "         [-0.2373],\n",
       "         [-0.5742],\n",
       "         [ 0.3602],\n",
       "         [ 1.2446],\n",
       "         [-0.0769],\n",
       "         [ 1.2005],\n",
       "         [ 0.4719],\n",
       "         [ 0.1083],\n",
       "         [ 0.9863],\n",
       "         [ 0.2135],\n",
       "         [ 0.6928],\n",
       "         [-0.2551],\n",
       "         [ 1.1368],\n",
       "         [ 0.8891],\n",
       "         [-0.7371],\n",
       "         [ 0.6818],\n",
       "         [ 0.5810],\n",
       "         [ 0.1427],\n",
       "         [ 0.0877],\n",
       "         [ 0.3705],\n",
       "         [-0.3966],\n",
       "         [ 1.0829],\n",
       "         [-1.2998],\n",
       "         [ 0.6475],\n",
       "         [ 0.7256],\n",
       "         [-0.1881],\n",
       "         [-0.2229],\n",
       "         [ 0.2951],\n",
       "         [ 0.0521],\n",
       "         [-0.1444],\n",
       "         [-0.1372],\n",
       "         [ 0.1905],\n",
       "         [ 0.4573],\n",
       "         [ 0.2788],\n",
       "         [-0.6252],\n",
       "         [-0.3742],\n",
       "         [ 0.4679],\n",
       "         [ 1.0019],\n",
       "         [ 0.5239],\n",
       "         [-0.1724],\n",
       "         [-0.2168],\n",
       "         [ 1.0176],\n",
       "         [ 1.3741],\n",
       "         [-0.7634],\n",
       "         [-0.1070],\n",
       "         [ 1.9405],\n",
       "         [ 0.4307],\n",
       "         [ 0.5244],\n",
       "         [ 0.7961],\n",
       "         [ 0.7867],\n",
       "         [ 0.2098],\n",
       "         [ 0.8638],\n",
       "         [ 0.2854],\n",
       "         [-0.6017],\n",
       "         [ 1.3913],\n",
       "         [-1.0860],\n",
       "         [-0.0221],\n",
       "         [ 0.7740],\n",
       "         [ 0.1996],\n",
       "         [ 0.4028]]),\n",
       " 'epochLoss': tensor([1.4158, 0.9615, 0.6554, 0.7426, 1.3452, 0.8609, 0.8976, 0.8243, 0.5819,\n",
       "         0.9856, 1.1887, 1.2180, 0.5890, 0.8031, 0.8416, 0.4595, 0.9538, 1.1380,\n",
       "         0.5138, 0.9918, 0.4034, 2.3305, 1.0271, 1.4185, 1.7564, 1.0228, 1.8212,\n",
       "         0.7938, 1.2512, 0.5172, 1.0467, 1.2211, 0.6804, 0.6556, 1.0479, 0.4445,\n",
       "         1.0695, 1.4880, 0.7428, 1.1425, 0.7595, 1.0687, 2.1399, 0.4200, 0.9456,\n",
       "         1.0067, 0.8506, 1.2386, 1.0468, 0.3371])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainOneEpoch(net,dataloader,optimizer,lossFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([])\n",
    "b=torch.tensor([1,2])\n",
    "c=torch.concat([a,b],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\project_meta\\NNproject\\NNI\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "root=os.path.abspath(os.path.join(r\"D:\\project_meta\\NNproject\\NNI\\notebook\\NNITest_0231104.ipynb\",\"../..\"))\n",
    "print(root)\n",
    "sys.path.append(root)\n",
    "os.environ[\"TORCH_HOME\"]=r\"E:\\Data\\torch-model\"\n",
    "from project.dataset.SelfDataset import TableControlFullLoadDataset\n",
    "from project.dataprocess.FolderTree import *\n",
    "import pandas as pd\n",
    "\n",
    "datasetDict=getDataPath(r\"D:\\dataset\\driver_dataset\\DROZY\\DROZY\")\n",
    "outputDict=getOutPath(r\"D:\\project_meta\\NNproject\\NNI\\output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LEVELDataset(TableControlFullLoadDataset):\n",
    "    def __getitem__(self, index):\n",
    "        superreturn = super().__getitem__(index)\n",
    "        return torch.tensor(superreturn['data']).to(torch.float32),torch.tensor(superreturn['LEVEL']).long()\n",
    "infoTable=pd.read_csv(outputDict['info_file'])\n",
    "dataset=LEVELDataset(infoTable,data_root=r\"D:\\dataset\\driver_dataset\\DROZY\\DROZY\",output_root=r\"D:\\project_meta\\NNproject\\NNI\\output\")\n",
    "from torch.utils.data import *\n",
    "dataloader=DataLoader(dataset,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [3, 16, 7680]             576\n",
      "       BatchNorm1d-2              [3, 16, 7680]              32\n",
      "              ReLU-3              [3, 16, 7680]               0\n",
      "         MaxPool1d-4              [3, 16, 3839]               0\n",
      "            Conv1d-5              [3, 32, 1920]           1,568\n",
      "       BatchNorm1d-6              [3, 32, 1920]              64\n",
      "              ReLU-7              [3, 32, 1920]               0\n",
      "            Conv1d-8               [3, 64, 960]           6,208\n",
      "       BatchNorm1d-9               [3, 64, 960]             128\n",
      "             ReLU-10               [3, 64, 960]               0\n",
      "           Conv1d-11               [3, 64, 480]          12,352\n",
      "      BatchNorm1d-12               [3, 64, 480]             128\n",
      "             ReLU-13               [3, 64, 480]               0\n",
      "           Conv1d-14               [3, 64, 240]          12,352\n",
      "      BatchNorm1d-15               [3, 64, 240]             128\n",
      "             ReLU-16               [3, 64, 240]               0\n",
      "AdaptiveAvgPool1d-17                 [3, 64, 1]               0\n",
      "          Flatten-18                    [3, 64]               0\n",
      "             ReLU-19                    [3, 64]               0\n",
      "           Linear-20                    [3, 32]           2,080\n",
      "             ReLU-21                    [3, 32]               0\n",
      "           Linear-22                     [3, 4]             132\n",
      "================================================================\n",
      "Total params: 35,748\n",
      "Trainable params: 35,748\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.44\n",
      "Forward/backward pass size (MB): 21.45\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 22.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from project.model.CNN1D import simple_cnn1d\n",
    "cnn=simple_cnn1d(input_channels=5,num_classes=4,list_down=[16,32,64,64,64])\n",
    "from torchsummary import summary\n",
    "summary(cnn,(5,3*2560),batch_size=3,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\1-1-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1, 1]),\n",
       " tensor([[ 0.1976, -0.4182,  0.2427,  0.3306],\n",
       "         [ 0.1235, -0.4830,  0.3132,  0.3182],\n",
       "         [ 0.1396, -0.3852,  0.1962,  0.3259]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from project.train.operation import *\n",
    "from torch import nn\n",
    "optimizer=torch.optim.Adam(cnn.parameters(),lr=0.001)\n",
    "lossFunction=nn.CrossEntropyLoss()\n",
    "\n",
    "forwardBatch(cnn,next(iter(dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\1-2-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\1-3-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\10-1-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\10-3-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\11-1-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\11-2-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\11-3-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\12-1-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\13-1-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\13-2-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\14-1-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\14-2-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\14-3-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\2-1-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\2-2-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\2-3-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\3-1-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\3-2-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\3-3-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\4-1-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\4-2-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\4-3-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\5-1-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\5-2-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\5-3-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\6-1-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\6-2-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\6-3-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\7-2-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\7-3-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\8-1-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\8-2-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\8-3-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\9-2-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n",
      "D:\\project_meta\\NNproject\\NNI\\project\\dataset\\SelfDataset.py:211: RuntimeWarning: This filename (D:\\project_meta\\NNproject\\NNI\\output\\psg_uniformfilted\\9-3-EEG.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  self.psg_file = mne.io.read_raw_fif(os.path.join(self.out_path_dict[\"uniformfilted_folder\"], file_name),verbose=False)\n"
     ]
    }
   ],
   "source": [
    "trainEpochs(1,cnn,dataloader,dataloader,optimizer,lossFunction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
