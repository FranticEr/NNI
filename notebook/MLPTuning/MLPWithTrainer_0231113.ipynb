{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设定路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\project_meta\\NNproject\\NNI\n"
     ]
    }
   ],
   "source": [
    "def setProjectPath(projectPath):\n",
    "    import os\n",
    "    import sys\n",
    "    root=os.path.abspath(projectPath)\n",
    "    print(root)\n",
    "    sys.path.append(root)\n",
    "    os.environ[\"TORCH_HOME\"]=r\"E:\\Data\\torch-model\"\n",
    "    import warnings  \n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"mne\")\n",
    "\n",
    "projectPath=r'D:\\project_meta\\NNproject\\NNI'\n",
    "setProjectPath(projectPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验一\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from project.dataset.SelfDataset import TableControlFullLoadDataset\n",
    "from project.dataprocess import FolderTree\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset, SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from typing import Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableDataset(Dataset):\n",
    "    def __init__(self,table:pd.DataFrame) -> None:\n",
    "        super().__init__()\n",
    "        self.Table=table\n",
    "    def __len__(self):\n",
    "        return len(self.Table)\n",
    "    def __getitem__(self, index) -> Any:\n",
    "        # torch.tensor(trainDataTable.drop(columns=['ID','KSS','LEVEL']).iloc[1].values)\n",
    "        x=torch.tensor(self.Table.drop(columns=['ID','KSS','LEVEL']).iloc[index].values).to(torch.float32)\n",
    "        y=torch.tensor(self.Table['LEVEL'].iloc[index]).long()-1\n",
    "        return x,y\n",
    "#路径\n",
    "data_root=r'D:\\dataset\\driver_dataset\\DROZY\\DROZY'\n",
    "output_root=r\"D:\\project_meta\\NNproject\\NNI\\output\"\n",
    "\n",
    "data_path_dict=FolderTree.getDataPath(data_root=data_root)\n",
    "output_path_dic=FolderTree.getOutPath(output_root=output_root)\n",
    "\n",
    "#表\n",
    "bandPowerTable=pd.read_csv(r\"D:\\project_meta\\NNproject\\NNI\\output\\bandpoweruniform.csv\")\n",
    "#数据集分割\n",
    "trainDataTable,testDataTable=train_test_split(bandPowerTable,test_size=0.35,shuffle=True)\n",
    "\n",
    "#数据加载器\n",
    "train_dataset=TableDataset(trainDataTable)\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=512,shuffle=True)\n",
    "\n",
    "test_dataset=TableDataset(testDataTable)\n",
    "test_dataloader=DataLoader(test_dataset,batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(trainDataTable['ID'].iloc[1])\n",
    "torch.tensor(trainDataTable['ID'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "def MLP(numFeature,interWidth,classes):\n",
    "    interWidth.insert(0,numFeature)\n",
    "    interWidth.append(classes)\n",
    "    net=nn.Sequential()\n",
    "    for i in range(len(interWidth)-2) :\n",
    "        net.append(nn.Linear(interWidth[i],interWidth[i+1]))\n",
    "        #net.append(nn.Dropout(0.5))\n",
    "        net.append(nn.ReLU())\n",
    "    net.append(nn.Linear(interWidth[-2],interWidth[-1]))\n",
    "    return net\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据维度：25\n",
      "类别数：25\n",
      "InterWidth [32, 64, 16]\n",
      "Sequential(\n",
      "  (0): Linear(in_features=25, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=16, out_features=25, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [5, 1, 32]             832\n",
      "              ReLU-2                 [5, 1, 32]               0\n",
      "            Linear-3                 [5, 1, 64]           2,112\n",
      "              ReLU-4                 [5, 1, 64]               0\n",
      "            Linear-5                 [5, 1, 16]           1,040\n",
      "              ReLU-6                 [5, 1, 16]               0\n",
      "            Linear-7                 [5, 1, 25]             425\n",
      "================================================================\n",
      "Total params: 4,409\n",
      "Trainable params: 4,409\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "InterWidth=[32,64,16]\n",
    "batch=next(iter(train_dataloader))\n",
    "NumFeature=(batch[0]).shape[-1]\n",
    "classes=NumFeature\n",
    "print(f'数据维度：{NumFeature}\\n类别数：{classes}')\n",
    "\n",
    "print(\"InterWidth\",InterWidth)\n",
    "\n",
    "net=MLP(numFeature=NumFeature,interWidth=InterWidth,classes=classes)\n",
    "print(net)\n",
    "summary(net,(1,NumFeature),batch_size=5,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=next(iter(train_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 25])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数权重存储路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\project_meta\\NNproject\\NNI\\output\\model_parameter\\FilterSignalCNN1D\\2023_11_13_12_41_27\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device=torch.device('cuda')\n",
    "current_time = datetime.datetime.now()\n",
    "formatted_time = current_time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "parameterFolder=os.path.join(r\"D:\\project_meta\\NNproject\\NNI\\output\\model_parameter\\FilterSignalCNN1D\",f\"{formatted_time}\")\n",
    "print(parameterFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=0.5\n",
    "Optimizer=torch.optim.SGD\n",
    "LossFuntion=nn.CrossEntropyLoss\n",
    "LRScheduler=torch.optim.lr_scheduler.StepLR\n",
    "StepLRGamma=0.7\n",
    "StepLRStep=80\n",
    "LayerSet=[256, 512, 64, 3]\n",
    "NumFeature=batch[0].shape[-1]\n",
    "LevelClasses=3\n",
    "KSSClasses=10\n",
    "EochsNum=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=MLP(NumFeature,LayerSet,LevelClasses)\n",
    "optim=Optimizer(net.parameters(),lr=LR,)\n",
    "lrScheduler=LRScheduler(optim,StepLRStep,StepLRGamma)\n",
    "lossFuntion=LossFuntion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 25])\n"
     ]
    }
   ],
   "source": [
    "batch[0].to(torch.device('cpu'))\n",
    "net.to(torch.device('cpu'))\n",
    "x=batch[0]\n",
    "print(x.shape)\n",
    "y_hat=net(x)\n",
    "y=batch[1]\n",
    "lossf=torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512]) torch.Size([512, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Frantic\\AppData\\Local\\Temp\\ipykernel_26816\\3759476486.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  lossf(y_hat,torch.tensor(y)-1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.1202, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat=torch.squeeze(y_hat, dim=1)\n",
    "print(y.shape,y_hat.shape)\n",
    "lossf(y_hat,torch.tensor(y)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\project_meta\\NNproject\\NNI\\output\\model_parameter\\FilterSignalCNN1D\\2023_11_13_12_25_18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25, out_features=25, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=25, out_features=256, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): Linear(in_features=64, out_features=3, bias=True)\n",
       "  (9): ReLU()\n",
       "  (10): Linear(in_features=3, out_features=3, bias=True)\n",
       "  (11): ReLU()\n",
       "  (12): Linear(in_features=3, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_time = datetime.datetime.now()\n",
    "formatted_time = current_time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "parameterFolder=os.path.join(r\"D:\\project_meta\\NNproject\\NNI\\output\\model_parameter\\FilterSignalCNN1D\",f\"{formatted_time}\")\n",
    "print(parameterFolder)\n",
    "os.makedirs(parameterFolder)\n",
    "\n",
    "best_train_acc=0\n",
    "best_train_loss=0\n",
    "best_test_acc=0\n",
    "stagnate_times=0\n",
    "temp_acc=0\n",
    "num_batches = len(train_dataloader)\n",
    "device=torch.device('cuda')\n",
    "net.to(device)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 0, 0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 1, 1, 0, 1, 2, 2, 1, 2, 1, 0, 1, 2,\n",
       "         2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 0, 1, 2, 1, 2, 0, 2, 1, 2, 2, 1, 0, 0, 2,\n",
       "         2, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1, 2, 1, 2, 0, 1, 1, 0, 0, 0, 2,\n",
       "         2, 2, 0, 2, 2, 0, 2, 1, 1, 0, 2, 0, 2, 2, 0, 1, 0, 0, 1, 0, 1, 2, 0, 2,\n",
       "         1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 2, 2, 0, 0, 2, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "         0, 1, 1, 0, 2, 1, 2, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "         0, 1, 1, 2, 0, 0, 2, 0, 0, 0, 2, 1, 2, 2, 0, 2, 2, 1, 0, 0, 2, 1, 0, 2,\n",
       "         0, 1, 2, 0, 2, 0, 0, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 0, 2, 0, 1,\n",
       "         1, 2, 2, 1, 0, 1, 1, 1, 1, 2, 1, 0, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1,\n",
       "         1, 1, 1, 1, 2, 1, 2, 1, 2, 0, 2, 1, 2, 1, 2, 0, 0, 1, 1, 1, 1, 0, 2, 2,\n",
       "         0, 2, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 2, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1,\n",
       "         2, 2, 2, 0, 2, 2, 1, 0, 1, 0, 1, 0, 1, 1, 1, 2, 0, 2, 1, 1, 1, 2, 1, 2,\n",
       "         1, 2, 1, 1, 2, 0, 0, 0, 2, 1, 1, 0, 1, 1, 2, 0, 0, 1, 2, 0, 0, 0, 0, 1,\n",
       "         1, 2, 1, 2, 0, 2, 0, 0, 1, 2, 1, 2, 1, 0, 2, 2, 1, 2, 1, 1, 0, 0, 1, 0,\n",
       "         0, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 0, 0, 0, 2, 2, 1, 2, 0, 1, 2, 2, 2, 0,\n",
       "         0, 2, 0, 1, 2, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 2, 0, 2, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 1, 1, 2, 0, 1, 2, 1, 0, 2, 2, 1, 0, 2, 2, 0, 2, 1, 2,\n",
       "         2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 0, 0, 0, 2, 1, 1, 2, 0, 2, 2,\n",
       "         2, 0, 0, 2, 2, 0, 2, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 2, 0, 1, 2,\n",
       "         1, 0, 0, 1, 0, 1, 2, 0, 2, 1, 2, 2, 0, 0, 1, 2, 0, 1, 0, 1, 2, 1, 0, 1,\n",
       "         2, 2, 2, 2, 0, 2, 0, 1, 2, 1, 0, 1, 2, 1, 1, 2, 2, 0, 2, 1, 1, 0, 0, 1,\n",
       "         1, 1, 1, 0, 1, 0, 1, 1]),\n",
       " tensor([[ 0.1235, -0.1223,  0.0449,  ..., -0.0520,  0.0155,  0.1521],\n",
       "         [ 0.1150, -0.1196,  0.0438,  ..., -0.0679,  0.0046,  0.1435],\n",
       "         [ 0.1181, -0.1184,  0.0447,  ..., -0.0535,  0.0181,  0.1487],\n",
       "         ...,\n",
       "         [ 0.1160, -0.1226,  0.0388,  ..., -0.0678,  0.0055,  0.1373],\n",
       "         [ 0.1202, -0.1227,  0.0426,  ..., -0.0663,  0.0034,  0.1428],\n",
       "         [ 0.1217, -0.1238,  0.0415,  ..., -0.0607,  0.0104,  0.1439]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor(3.2059, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from project.trainer.ClassfierTrainer import ClassfierTrainer\n",
    "trianer=ClassfierTrainer(net,EochsNum,optim,lossFuntion)\n",
    "batch=next(iter(train_dataloader))\n",
    "trianer.TrainBatch(net.to(torch.device('cpu')),batchData=batch,optimizer=optim,lossFunction=lossFuntion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from project.dataset.SelfDataset import TensorTableDataset,TableDataset\n",
    "from project.dataprocess import FolderTree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset, SubsetRandomSampler\n",
    "import pandas as pd\n",
    "#路径\n",
    "data_root=r'D:\\dataset\\driver_dataset\\DROZY\\DROZY'\n",
    "output_root=r\"D:\\project_meta\\NNproject\\NNI\\output\"\n",
    "\n",
    "data_path_dict=FolderTree.getDataPath(data_root=data_root)\n",
    "output_path_dic=FolderTree.getOutPath(output_root=output_root)\n",
    "class BandPowerDataset(TableDataset):\n",
    "    def __getitem__(self, index) -> Any:\n",
    "        x,y=super().__getitem__(index)\n",
    "        return x,y-1\n",
    "#表\n",
    "bandPowerTable=pd.read_csv(r\"D:\\project_meta\\NNproject\\NNI\\output\\bandpoweruniform.csv\")\n",
    "#数据集分割\n",
    "trainDataTable,testDataTable=train_test_split(bandPowerTable,test_size=0.35,shuffle=True)\n",
    "\n",
    "#数据加载器\n",
    "train_dataset=BandPowerDataset(trainDataTable,label='LEVEL',drop=['KSS','ID'])\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=512,shuffle=True)\n",
    "\n",
    "test_dataset=BandPowerDataset(testDataTable,label='LEVEL',drop=['KSS','ID'])\n",
    "test_dataloader=DataLoader(test_dataset,batch_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.8617, 0.0863, 0.0094,  ..., 0.0347, 0.0970, 0.1038],\n",
       "         [0.5527, 0.2558, 0.0298,  ..., 0.1395, 0.2074, 0.1934],\n",
       "         [0.6498, 0.0562, 0.1105,  ..., 0.4304, 0.3015, 0.0298],\n",
       "         ...,\n",
       "         [0.4314, 0.2560, 0.1974,  ..., 0.3525, 0.1686, 0.0985],\n",
       "         [0.4458, 0.1740, 0.0820,  ..., 0.1834, 0.2510, 0.1910],\n",
       "         [0.8975, 0.0219, 0.0092,  ..., 0.0623, 0.2797, 0.1872]]),\n",
       " tensor([1, 0, 1, 2, 0, 1, 2, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 2, 2, 0, 1, 0, 0, 2,\n",
       "         1, 1, 0, 0, 1, 1, 0, 2, 1, 0, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 0, 1, 0, 1,\n",
       "         1, 2, 2, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 2, 1, 2, 2, 2, 0, 0, 1, 2, 1,\n",
       "         1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 0, 2, 1, 2,\n",
       "         1, 1, 2, 0, 0, 2, 1, 0, 1, 1, 0, 1, 0, 1, 2, 0, 1, 1, 0, 2, 2, 2, 0, 0,\n",
       "         0, 2, 2, 2, 2, 2, 0, 1, 0, 1, 0, 2, 2, 1, 1, 2, 1, 2, 1, 1, 0, 1, 1, 2,\n",
       "         1, 1, 2, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "         1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 1, 2, 2, 0, 2, 2, 0,\n",
       "         0, 2, 2, 1, 1, 1, 1, 0, 1, 1, 2, 0, 1, 0, 1, 1, 2, 0, 2, 0, 2, 1, 0, 1,\n",
       "         1, 2, 2, 1, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2, 1, 0, 1, 2, 1, 0, 2,\n",
       "         0, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 1, 0, 2, 0, 0, 1, 1, 2, 0, 1, 1, 2, 0,\n",
       "         0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 2, 1, 2, 2, 1, 1, 1, 1, 0, 0, 0, 1, 1, 2,\n",
       "         0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 2, 1, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1,\n",
       "         2, 2, 1, 1, 2, 0, 1, 1, 1, 2, 0, 0, 0, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2,\n",
       "         2, 0, 2, 1, 2, 0, 1, 1, 0, 1, 0, 1, 2, 2, 2, 2, 1, 2, 2, 0, 1, 2, 1, 0,\n",
       "         1, 1, 1, 0, 2, 1, 1, 2, 1, 1, 2, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0, 0,\n",
       "         2, 0, 1, 1, 0, 2, 0, 2, 0, 1, 1, 2, 1, 2, 2, 0, 2, 1, 2, 0, 2, 1, 0, 0,\n",
       "         0, 2, 0, 0, 1, 2, 1, 0, 1, 2, 0, 1, 1, 2, 2, 0, 0, 1, 0, 2, 2, 2, 0, 0,\n",
       "         1, 0, 0, 1, 2, 0, 0, 2, 0, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 0, 2, 0, 0, 1,\n",
       "         1, 2, 2, 0, 2, 1, 1, 0, 1, 2, 0, 0, 1, 2, 2, 2, 2, 0, 1, 0, 1, 1, 1, 2,\n",
       "         0, 0, 1, 0, 0, 0, 0, 1, 2, 2, 1, 2, 1, 2, 0, 1, 1, 2, 2, 0, 1, 0, 2, 0,\n",
       "         1, 2, 2, 2, 2, 0, 2, 1])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
